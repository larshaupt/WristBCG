# WristBCG

WristBCG is part of my master's thesis, aiming at estimating the heart rate from wrist-worn accelerometers while asleep.

For the results, please refer to my [thesis](Master_Thesis_Lars_Hauptmann.pdf).

## Installation Requirements
To install the required packages, run the following code. The current Pytorch version is 2.2.1:

```
conda env create -f environment.yml
```


## Training

To train the models for all the experiments described in my thesis, you can execute the following commands for each experiment. These will use the specified configurations for training the models:

```
# Supervised
python main.py --framework supervised --dataset appleall

# Self-Supervised Learning
python main.py --framework nnclr --aug1 t_warp --aug2 bioglass --pretrain 1 --finetune 1 --dataset appleall --pretrain_dataset capture24

# With Postprocessing
python main.py --framework supervised --finetune 1 --model_uncertainty NLE --postprocessing sumprod --dataset appleall

# With Postprocessing and Self-Supervised Learning
python main.py --framework nnclr --aug1 t_warp --aug2 bioglass --pretrain_subsample 0.2 --pretrain 1 --finetune 1 --model_uncertainty NLE --postprocessing sumprod --dataset appleall
```

These commands will allow you to train the models under various settings, including supervised learning, self-supervised learning, and combinations with postprocessing techniques.



## Inference

Once training is complete, is automically runs inference on the testing set and reports the results to wandb. Given the pretrained models in [results](results), you can also directly run inference via:

```
# Supervised
python main.py --framework supervised --dataset appleall --finetune 0

# Self-supervised
python main.py --framework nnclr --aug1 t_warp --aug2 bioglass --pretrain 0 --finetune 0 --dataset appleall --pretrain_dataset capture24

# With Postprocessing
python main.py --framework supervised --finetune 0 --model_uncertainty NLE --postprocessing sumprod --dataset appleall

# With Postprocessing and Self-Supervised Learning
python main.py --framework nnclr --aug1 t_warp --aug2 bioglass --pretrain_subsample 0.2 --pretrain 0 --finetune 0 --model_uncertainty NLE --postprocessing sumprod --dataset appleall
```

## Replicating Experiments

To replicate the experiments and generate plots, follow these steps:

### Step 1: Running Weights and Biases (WandB) Experiments

1. **Login to WandB**:
   ```
   wandb login
   ```

2. **Execute the sweep command** to run all the configurations for your experiments:
   ```
   wandb sweep --project WristBCG LINK_TO_REPO/sweep_config/supervised_train.yaml
   ```

3. **Start the agent** after getting the `SWEEP_ID` from the previous step:
   ```
   wandb agent SWEEP_ID
   ```

4. **Track progress** and results of the sweep on your WandB dashboard. The agent will execute the sweep and automatically run the experiments.

### Step 2: Generating Plots from the Results

After running the experiments via WandB, use the `make_wandb_plots.py` script to generate comparative plots.

1. **Run the `make_wandb_plots.py` script** with the sweep IDs of the experiments you want to compare:

   ```
   python make_wandb_plots.py --sweep_ids SWEEP_ID_1 SWEEP_ID_2
   ```

2. **Review the generated plots** for performance comparisons, visualizing metrics like accuracy, loss, and other relevant results from your experiments.

### Step 3: Analyze Results

Use the plots and tables generated by `make_wandb_plots.py` to analyze the performance of different models, hyperparameters, or configurations. You can compare experiments side by side, such as those using supervised learning, self-supervised learning, or postprocessing methods.

## Supported Datasets
- Apple Watch [link](https://www.physionet.org/content/sleep-accel/1.0.0/) (with labels)
- Capture24 [link](https://github.com/OxWearables/capture24) (without labels)
- In-House dataset (to be published soon)

## Data Split Cases
- subject: perform the split along subjects, i.e., the same subject is only in the train or test set
- time: perform the split for each subject along time dimensions, i.e., splits each recording into n continuous segments

## Encoder Networks
Refer to `models/backbones.py`
- CorNET (adapted from Biswas et al. CorNET: Deep Learning Framework for PPG-Based Heart Rate Estimation and Biometric Identification in Ambulant Environment)
- FrequencyCorNET (stacks fft-derived spectrogram on top of signal)
- AttentionCorNET (adds channel attention)
- FCN
- DeepConvLSTM
- LSTM
- AE
- CAE
- Transformer
- HRCTPNet (ConvTransformer, see Zhang et al. A Conv-Transformer network for heart rate estimation using ballistocardiographic signals)
- ResNET (see [link](https://github.com/OxWearables/ssl-wearables))

<br>To train an encoder network under supervised setting, you can run the following code:

```
python main.py --framework supervised --backbone CorNET
python main.py --framework supervised --backbone FCN
...
```

## Contrastive Models
Refer to `models/frameworks.py`. For sub-modules (projectors, predictors) in the frameworks, refer to `models/backbones.py`
- TS-TCC
- SimSiam
- BYOL
- SimCLR
- NNCLR

## Augmentations
Refer to `augmentations.py`
- ### Time Domain
  - noise
  - scale
  - negate
  - perm
  - shuffle
  - t_flip
  - t_warp
  - resample
  - rotation
  - perm_jit
  - jit_scal
  - bioinsights

- ### Frequency Domain
  - hfc
  - lfc
  - p_shift
  - ap_p
  - ap_f
  - bioinsights

## Utils
- WandB
- t-SNE

## Related Links
The framework has been adapted from
- https://github.com/Tian0426/CL-HAR

Part of the augmentation transformation functions are adapted from
- https://github.com/emadeldeen24/TS-TCC
- https://github.com/terryum/Data-Augmentation-For-Wearable-Sensor-Data
- https://github.com/LijieFan/AdvCL/blob/main/fr_util.py

Part of the contrastive models are adapted from
- https://github.com/lucidrains/byol-pytorch
- https://github.com/lightly-ai/lightly
- https://github.com/emadeldeen24/TS-TCC

The ResNET model and pretrained weight have been taken from
- https://github.com/OxWearables/ssl-wearables

The BeliefPPG and Viterbi algorithm have been adapted from
- https://github.com/eth-siplab/BeliefPPG
